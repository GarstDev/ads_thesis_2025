# Evaluating Hospital Action Plans Using GPT-4
This repository contains the notebook used for the analytical work presented in my thesis for Applied Data Science, focusing on the evaluation of the GPT model performance and consistency. 

## Key Analyses Performed
This notebook conducts the following analyses: 
1. Cohen's Kappa Agreement
2. ROUGE evaluation
3. Semantic Similarity (BERTScore)

## Code 
The '.ipynb' file contains all the python scripts used during this thesis project. To ensure that everything runs correctly, the scripts should be run **sequentially** starting from the first cell. 

## Data
To run the analysis in this notebook, please ensure:
- Files are encoded in UTF-8
- Use `;` as the field separator
- Fields containing commas should be enclosed in double quotes

Due to privacy measures the **data is not publicly available**. To run this code, the data you must provide is outlined below.  

1. Main Evaluation Dataset: this dataset must be provided in order to evaluate label agreement (Cohen's Kappa), ROUGE scores, and semantic similarity by comparing human annotations with LLM model outputs.

**Required Columns:**

* `case_id`: (String) The case identifier (A through I).
* `criteria`: (String) The specific evaluation criterion being assessed (e.g., scale of plan).
* `human_label`: (String) The classification label provided by the human expert.
* `cot_gpt_label`: (String) The classification label generated by the LLM model using the "Chain of Thought" (CoT) prompting strategy.
* `mp_gpt_label`: (String) The classification label generated by the LLM model using the "Metacognitive Prompting" (MP) strategy.
* `ps_gpt_label`: (String) The classification label generated by the LLM model using the "Plan-and-Solve" (PaS) strategy.
* `sc_gpt_label`: (String) The classification label generated by the LLM model using the "Self-Consistency" (SC) strategy.
* `human_explanation`: (String) The explanation provided by the human expert.
* `cot_gpt_explanation`: (String) The explanation generated by the LLM model using the CoT strategy.
* `mp_gpt_explanation`: (String) The explanation generated by the LLM model using the MP strategy.
* `ps_gpt_explanation`: (String) The explanation generated by the LLM model using the PaS strategy.
* `sc_gpt_explanation`: (String) The explanation generated by the LLM model using the SC strategy.

2. Consistency Check Dataset: this dataset is used to evaluate the internal consistency of the LLM model themselves by comparing outputs of two different runs of the same prompting strategy for identical inputs.

**Required Columns:**

* `case_id`: (String) The case identifier (A through I).
* `criteria`: (String) The specific evaluation criterion being assessed for the case (e.g., scale of plan).
* `cot1`: (String) The classification label from the first run of the CoT strategy.
* `cot2`: (String) The classification label from the second run of the CoT strategy.
* `mp1`: (String) The classification label from the first run of the MP strategy.
* `mp2`: (String) The classification label from the second run of the MP strategy.
* `ps1`: (String) The classification label from the first run of the PaS strategy.
* `ps2`: (String) The classification label from the second run of the PaS strategy.
   
