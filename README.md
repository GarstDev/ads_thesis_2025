This repository contains the notebook used for the analytical work presented in my thesis, focusing on the evaluation of the GPT model performance and consistency. 

## Key Analyses Performed
This notebook conducts the following analyses: 
1. Cohen's Kappa Agreement
2. ROUGE evaluation
3. Semantic Similarity (BERTScore)

## Data Requirements
To run the analysis in this notebook, you will need two primary datasets, provided as CSV files. Ensure that all CSV files are encoded in 'UTF-8,' use a ';' as separator, and fields containing commas are enclosed in double quotes. 
Due to privacy measures the data is not publicly available. 

1. Main Evaluation Dataset: this dataset must be provided in order to evaluate label agreement (Cohen's Kappa), ROUGE scores, and semantic similarity by comparing human annotations with LLM model outputs.
**Required Columns:**

* `case_id`: (String/Integer) A unique identifier for each individual case or record.
* `criteria`: (String) The specific evaluation criterion or question being assessed for the case.
* `human_label`: (String) The classification label provided by the human expert.
* `cot_gpt_label`: (String) The classification label generated by the GPT model using the "Chain of Thought" (CoT) prompting strategy.
* `mp_gpt_label`: (String) The classification label generated by the GPT model using the "Multiple Prompts" (MP) strategy.
* `ps_gpt_label`: (String) The classification label generated by the GPT model using the "Persona Simulation" (PS) strategy.
* `sc_gpt_label`: (String) The classification label generated by the GPT model using the "Self-Correction" (SC) strategy.
* `human_explanation`: (String) The explanation or reasoning provided by the human expert.
* `cot_gpt_explanation`: (String) The explanation generated by the GPT model using the CoT strategy.
* `mp_gpt_explanation`: (String) The explanation generated by the GPT model using the MP strategy.
* `ps_gpt_explanation`: (String) The explanation generated by the GPT model using the PS strategy.
* `sc_gpt_explanation`: (String) The explanation generated by the GPT model using the SC strategy.

2. Consistency Check Dataset: this dataset is used to evaluate the internal consistency of the LLM model themselves by comparing outputs of two different runs of the same prompting strategy for identical inputs.
**Required Columns:**

* `case_id`: (String/Integer) A unique identifier for each individual case or record.
* `criteria`: (String) The specific evaluation criterion or question being assessed for the case.
* `cot1`: (String) The classification label from the first run of the "Chain of Thought" (CoT) strategy.
* `cot2`: (String) The classification label from the second run of the CoT strategy.
* `mp1`: (String) The classification label from the first run of the "Multiple Prompts" (MP) strategy.
* `mp2`: (String) The classification label from the second run of the MP strategy.
* `ps1`: (String) The classification label from the first run of the "Persona Simulation" (PS) strategy.
* `ps2`: (String) The classification label from the second run of the PS strategy.
   
